{
  "title": "Chapter 10: Channels",
  "cells": [
    {
      "type": "markdown",
      "data": "### 10.1 - Signaling Semantics\n\nOrchestration is performed via **channels**. We can share data between goroutines via channels.\n\nFocus on the signalling behavior of channels first.\n\n**Question 1**: does the sending goroutine need a guarantee that the receiving goroutine got its signal? Buffered channels have those guarantees, and unbuffered channels do not.\n**Question 2**: what's our channel behavior semantic? One-to-one of data? One-to-many? Are we transferring data or are we signalling?\n\nWe'll look at basic patterns to answer these questions.\n\n### 10.2 - Basic Patterns—Part 1 (Wait for Task)\nWe have an unbuffered channel that allows us guarantees on receiving. One goroutine sends, blocks until the other one receives; that other one has been blocking, waiting for something the whole time. It gets here data.\n\n### 10.2 - Basic Patterns—Part 2 (Wait for Result)\nThis is the opposite of \"wait for task\" - used for fanout patterns! \n\nWe start with an unbuffered channel - signalling with guarantees, sharing data. A goroutine starts doing some work for an unknown amount of time, and the main method waits to get its results.\n\n### 10.2 - Basic Patterns—Part 3 (Wait for Finished)\nThis pattern is better with a wait group - signalling with data.\n\nThe channel here is `make(chan struct{})`, which shows that we're signalling without data. Think open / close channels!\n\nWhen you close a channel, the receiver of that channel can deconstruct the args to detect that closed channel. `_, wd := <-ch`.\n\n### 10.3 - Pooling Pattern\nGuarantees (unbuffered) and string-based - this lets you do deadlines and timeouts later.\n\nWe range over the **same** channel on two goroutines, and then send work into that channel. The scheduler chooses which goroutine to send that work into. Goroutines will block until they're ready to receive more work. This is parallelization!\n\n### 10.4 - Fan Out Pattern\nNote - fanout patterns can be dangerous. Scaling to a huge number of goroutines will put load on underlying resources and the scheduler itself."
    }
  ]
}