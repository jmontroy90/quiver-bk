{
  "title": "Two Go Programs, Three Different Profiling Techniques",
  "cells": [
    {
      "type": "markdown",
      "data": "[Link to video](https://www.youtube.com/watch?v=nok0aYiGiYA)\n\n### Program #1 - Word Count\nHis program is slow. `wc` is two orders of magnitude faster. He uses his package around `pprof` to start the profiling. He adds to his program:\n\n```defer profile.Start(profile.CPUProfile, profile.ProfilePath(\".\")).Stop()```\n\nThen use `pprof` to check the results:\n\n```go tool pprof -http=:8080 cpu.pprof```\n\n`pprof` is simple - register an OS interrupt on all goroutines on same small interval. On each interrupt, take a snapshot of the call stack per goroutine. At the end, the call stacks that show up the most are the ones that have done the most work.\n\nHis `pprof` shows that `syscall` is taking up all of the CPU in the `main` goroutine (as opposed to the other `runtime` goroutines). This reflects **how many times** `syscall` is being called, not that it's called once and takes forever.\n\nThis ultimately is because of too many syscalls and no buffering. Fundamentally, this happens because of context switches between goroutines executing syscalls -- the syscall takes too long, a new goroutine is spun up once the current one exceeds its scheduling CPU slice time, we context switch for the next syscall, the old one routines, and churn and churn and churn.\n\nWe fix this via buffering! Fewer goroutines to manage, fewer (to no?) context switches. Change to the `bufio` package and you're off to the races.\n\nThis new `pprof` after buffering shows some random `runtime` goroutine call stacks -- the program runs so fast, not much is sampled from call stacks, and this CPU profile is essentially random now!\n\nBUT. Sometimes this CPU profile shows `mallocgc`, which is interesting! Let's do memory profiling now to find out more, e.g. `profile.MemProfile` from the `defer` call above.\n\nNote - the `MemProfile` also samples, this time every N allocations. You can change that amount.\n\nWe see that our allocation all comes from `main` in the form of `readbyte` allocations (`readbyte` is his function). This is ultimately because he allocates a `[1]byte` but uses it with an interface (`io.Reader`) -- this somehow causes the byte array to escape the stack and move to the heap, which means you're constantly allocating on heap. He fixes this by just re-using the same byte array, allocated outside of the function so it doesn't have to be stack-allocated and then escape to heap.\n\n### Program #2 - Mandelbrot\n\n"
    }
  ]
}