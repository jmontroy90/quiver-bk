{
  "title": "Chapter 19 - Load Balancing at the Front End",
  "cells": [
    {
      "type": "markdown",
      "data": "Load balancing between data centers (\"at the front end\") just means distributing traffic in an optimal fashion. This optimal fashion depends on:\n* The hierarchical level at which we evaluate the problem (global versus local)\n* The technical level at which we evaluate the problem (hardware versus software)\n* The nature of the traffic we’re dealing with\n\nSo a search request might minimize latency and route to the nearest datacenter, whereas a video upload will maximize throughput and will route to an underutilized DC it can saturate. But it can get way more complex.\n\nLet's examine two kinds of load balancing.\n\n### Load Balancing Using DNS\nA DNS nameserver returns the address closest to the query it recieves. The problem there is that DNS uses a lot of middleman servers. That means, without EDNS0 (implemented in OpenDNS), an authoritative nameserver will return the address closest to the middleman, not to the originating client:\n> For instance, a large national ISP might run nameservers for its entire network from one datacenter, yet have network interconnects in each metropolitan area. The ISP’s nameservers would then return a response with the IP address best suited for their datacenter, despite there being better network paths for all users!\n\nTTLs also make it difficult to know what a given middleman or authoritative nameserver will return. And even if you handle all these complexities, you still need to understand whether the IP you recieve corresponds to a datacenter / host that's even available to recieve traffic, let alone the type of traffic you need. No good if you get a dead endpoint.\n\n### Load Balancing at the Virtual IP Address\nVirtual IPs appear to the client as one IP, but allow for shifting, maintainable backends behind that VIP. Load balancing between them is a matter of using _consistent hashing_, which ensures that even if a backend dies, stateful requests (e.g. sessions for a single client that need to maintain state across requests) can usually be consistently routed to the right backend. This is different than simple modding the request by the number of backends -- if the number of backends changes, you're screwed.\n\nOnce a request reaches a VIP, it needs to routed to a backend. We can modify the L2 packet, e.g. the destined MAC address, but this requires all backends to reside in a single broadcast domain. It _does_ enables **Direct Server Response** (DSR), which is just the practice of replying to the client directly after recieving something from a load balancer, rather than flowing back through the load balancer.\n\nGoogle wraps packets in another IP packet with Generic Routing Encapsulation (GRE) -- this layer is stripped off by the recieving backend s.t. it can read the original request. This means load balancers can route to backends in totally separate broadcast domains, which is nice. It does mean packet sizes inflate, which can cause fragmentation without being savvy on your Maximum Transmission Units (MTUs).\n\nBear in mind -- when we say \"backend\" in this context, we literally mean entire datacenters."
    }
  ]
}