{
  "title": "Chapter 10 - Practical Alerting",
  "cells": [
    {
      "type": "markdown",
      "data": "This chapter describes Borgmon, which has basically the same syntax as Prometheus.\n\nMost important: **time series metrics**, with a common format and method for exposing them on services.\n\nEach time series constitutes a **vector**, e.g. data points over time in a sequence. The name of the time series is the **labelset**, which works like Prometheus label sets. Labels can be added by a service, a Prometheus instance, or a rule itself.\n\nThis is close, but not exact, to Prometheus syntax:\n```\n{var=http_requests,job=webserver,service=web,zone=us-west}[10m]\n```\n\nKeep your metrics and their rules simple, so that your metrics and alerting amount to nothing more than arithmetic on a big calculator!\n\n**Counters** are better than **gauges** -- a gauge runs that sorta CAS-esque risk, where any event between two measurements will be lost (e.g. T1 = 40, T2 = 40, in between it was 1 billion though!!).\n\nRules (aggregates of time series) can be used to trigger alerts. These alerts will be handled by **Alertmanager**, which deduplicates, fans out/in, and ensures that a rule is triggering for a period of time before firing the alert (to avoid **flapping**).\n\nAs previously discussed, pages to on-call should be novel events requiring human intervention. Important but non-critical alerts should just be tickets, and informational alerts should be logged for later evaluation.\n\nBear in mind that all this (Borgmon, Prometheus, TS metrics) is all **white-box monitoring** -- it won't help for services that are down or unreachable, e.g. **black-box monitoring** and **functional testing**. For this, Google uses **Prober**, which does user-facing checks (healthchecks, essentially) that also send alerts to Alertmanager. These checks need to be sensitive to load-balancing topologies, CDNs, etc. -- check both the front-end (a CNAME, maybe, or a load-balanced endpoint), AND all its backends.\n\nRules and alerts can be configured and templated. The templates can be patterned around labelling for locality (datacenter, shard), source (instance, task), and type (HTTP response code, CPU).\n\nGoogle runs integration suites on mocked TS data to ensure the results of queries are what we think. Also, rules are separate from their monitoring targets, so that we can write a rule once and apply it to many different hosts or datacenters."
    }
  ]
}