{
  "title": "CalicoCon",
  "cells": [
    {
      "type": "markdown",
      "data": "## Terms\n* `CNI`\n* `kube-proxy`\n* `IPSets` w/ `IPTables` (+ `eBPF`)\n* `XDP`\n* `DNAT` / `SNAT`\n* `GlobalNetworkPolicy` -- `applyOnForward`, `preDNAT`\n* `IPAM`, `VXLAN`, `IPIP`\n* `IPPool` --   `blockSize`, `ipipMode`, `natOutgoing`\n* `ECMP Anycast`\n\n## Session 1\nPods come and go -- how do we maintain stable network identities / management in the face of this transience? `Services` are the basic abstraction over a `kube-proxy` (glorified `iptables`), but things like Calico layer on Network Policies to create higher-level structures in your cluster.\n\nCalico is the default network policy tool for lots of K8s distributions  does two things:\n1) High-level declarative network policy -- mapped to low-level, dynamic networking rules that scalably implement your policy. This can help provide isolation within your cluster.\n2) All nodes are routers!\n\nThe Kubernetes network is flat -- all pods talk to all other pods, on any node. Additionally, everything is ephemeral (like IPs and pod locations), so higher-level policies allow a consistent structure to network interactions in the face of this ephemerality. This allows isolation, which is good for security -- an attacker who accesses one shitty app with vulnerabilities can't then run amok on other nodes / in other apps.\n\nThe `NetworkPolicy` resource works mostly with labels. Imagining denying a particular protocol from a particular CIDR range to some label set. So these policies map much better than traditional firewalls or manual iptables on IP ranges, since it works with first-class k8s primitives like labels and namespaces.\n\nCalico is a `DaemonSet` behind the scenes, where each node's Calico pod builds its particular filtering rules from the K8s API server's `NetworkPolicy` resources. Stays declarative, and scalable!\n\nThe Calico model makes no distinction between host endpoints (`kubelet` reaching out to the API server), and workload endpoints (an individual pod's protocol and port mapped to the host).\n\nThink of inverting control on your label hierarchies. A node can declare its ingress labels more generally, e.g. \"anyone who says that they're a database client can come in\", rather than updating granularly \"apps A, B, and C can come in\".\n\nStep 1: default deny! Step 2: everything else.\n\n## Session 2\n\nServices and Calico. He started with a lengthy overview of basic Kubernetes Services, which I've done before. Also showed some nice stuff on how Services jump to other IP / Ports based on DNAT (and SNAT on the way back if needed). We can see the stats on the services, on IPVS hits, on IPTables hits.\n\nIn this domain, Calico is meant to way reduce the overhead associated with expansive Service accumulation, where 100s of iptables rules are hit per Service lookup. IPSets, IPVS, etc. -- they're all meant to be smarter routers for scale, so we might need this as our clusters grow.\n\n**INGRESS**: `NodePort` is a very primitive, coarse way to give external access to your services. `ClusterIP` is only internal; `Ingress` is usually what people reach for. Calico can use BGP to actually peer a given service IP range (for your private `ClusterIP` services) to the external world! This means no fussing with `NodePort` or even `Ingress`. You can also advertise external IPs via `serviceExternalIPs`.\n\n\nMasquerading in `iptables` -- talked a bunch, gotta summarize here! And solidify!\n\n"
    }
  ]
}