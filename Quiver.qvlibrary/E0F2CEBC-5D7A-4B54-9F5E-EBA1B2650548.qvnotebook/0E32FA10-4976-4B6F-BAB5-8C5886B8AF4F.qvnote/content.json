{
  "title": "Chapter 1: An Introduction to Concurrency",
  "cells": [
    {
      "type": "markdown",
      "data": "Concurrency is traditionally about shared access to state. Why is concurrency hard?\n\n* **Data races**: scheduler contention, GC, excessive I/O -- they can all cause unexpected interleavings of your goroutines as they access memory.\n* **Atomicity**: most Go statements aren't atomic. They may look it, but who knows how the compiled CPU instructions might interleave. If something is truly atomic, great -- we can say it runs completely at one point in time. If not, there's room for interleaving.\n\nA **critical section** is a section of your code that needs exclusive access to a shared resource. If it doesn't have that exclusive access, the correctness of the code will be at risk.\n\nUsing **sync.Mutex** to lock critical sections will help with correctness, but your code won't necessarily be deterministic with locks alone. All of a critical section `A` accessing shared resource `x` will happen atomically when locked, but another critical section `B` might either access `x` before **or** after `A`. We don't know.\n\n**Deadlocks** are when two processes are trying to obtain access to resources held by the other process. Basically, if you have multiple shared resources whose locks can be acquired in any order, any concurrent processes nondeterministically acquiring those locks have a chance of deadlocking. Deadlocks aren't a problem if one process gives up its access, though. That's why Go (and SQL Server!) have deadlock victims.\n> The state of being deadlocked is described by the **Coffman Conditions**:\n> 1) Mutual Exclusion -- concurrent process has exclusive rights to a resource.\n> 2) Wait For Condition -- concurrent process exclusively holds a resource and is waiting for one more.\n> 3) No Preemption -- resources are only released by processes that hold them\n> 4) Circular Wait -- process P1 is waiting on P2, which is itself waiting on P1\n\n**Livelocks** are a trickier scenario where two processes keep trying to prevent a deadlock _without coordination_. So imagine a process being like, \"okay, if we can't access that shared resource, let's just let it go and try another shared resource\". But if two processes are BOTH doing that, they essentially keep getting in each other's way, and nothing progresses. There's lots of action -- CPU utilization, lock acquisitions, maybe metrics and other stuff depending on your app -- but no progress is being made on the shared resources. Like two people blocking each other by stepping in the same direction to let each other by, then trying the other direction -- \"your program would be playing an eternal game of hallway-shuffle.\n\n**Starvation** occurs because of unequal access to resources. For example, the size of a critical section matters -- a coarse-grained lock on a large critical section might be good for performance (not as much context / lock switching), but you run the risk of starving other, more granular processes of their time slices.\n\nBut Go is on your side. Goroutines are mapped to OS threads, scheduled fairly, and allow for shared memory access via **channels**."
    }
  ]
}