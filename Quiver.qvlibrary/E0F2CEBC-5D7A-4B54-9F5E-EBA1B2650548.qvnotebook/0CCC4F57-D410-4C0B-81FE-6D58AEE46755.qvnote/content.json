{
  "title": "Chapter 3: Go’s Concurrency Building Blocks",
  "cells": [
    {
      "type": "markdown",
      "data": "## Goroutines\nGoroutines are special `coroutines` -- they are scheduled onto green threads (runtime-managed), which are then mapped to OS threads. Coroutines are concurrent subprocesses that are `nonpreemptive` -- they can't be interrupted, but the Go runtime manages their suspension and reentry by simply observing their block points.\n\nGoroutines follow the `fork-join` concurrency model. That means that a goroutine forks off a main routine, and can be made to rejoin the main thread in the future. This is practically implemented by the `sync.WaitGroup` construct, which is a way of coordinating processes. Take this example:\n```\nsayHello := func() {\n    fmt.Println(\"hello\")\n}\ngo sayHello()\n```\n\nThere's no guarantee that \"hello\" will be printed, because the main goroutine might terminate before the `sayHello()` goroutine is scheduled. When you use the `go` keyword, it's just creating a goroutine to be scheduled and run. This is using the fork-join idea with `sync.WaitGroup`:\n```\nvar wg sync.WaitGroup\nsayHello := func() {\n    defer wg.Done()\n    fmt.Println(\"hello\")\n}\nwg.Add(1)\ngo sayHello()\nwg.Wait()\n```\n\nGoroutines can use lexical scope to capture variables, but be careful with this! What's the output here?\n```\nvar wg sync.WaitGroup\nfor _, salutation := range []string{\"hello\", \"greetings\", \"good day\"} {\n    wg.Add(1)\n    go func() {\n        defer wg.Done()\n        fmt.Println(salutation)\n    }()\n}\nwg.Wait()\n```\n\nYou might think the contents of the slice in some nondeterministic order, but this will likely print \"good day\" three times. Why? The closures capture the `salutation` variable via lexical scope. By the time a given goroutine is scheduled and run, the `for` loop has likely finished. That means the iteration variable `salutation` is on the last value and would normally be GCed. Because the goroutines need that variable lexically, the variable escapes to the heap as its last value, which is \"good day\". This applies for each goroutine, so they all print \"good day\". Tricky but interesting.\n\nThink of goroutines as simply \"hosting functions\". This is important with lexical scope because it helps understand why we need to synchronize goroutines with shared lexical access -- they share the address space.\n\nNote: **goroutines can leak!**\n\nThe book goes on to talk about size, growth, and context switching costs of goroutines. tl;dr -- it's low. Goroutines are about 2kb per, and cost switching in software is usually much faster than an OS. The runtime can control how things are persisted and accessed for context switching better than an OS can -- less running, more granularity.\n\n## The Sync Package\n**sync.WaitGroup** -- a simple \"counter\" for waiting for concurrent operations to complete. Create a `WaitGroup`, `wg.Add()` to it for each goroutine; those goroutines do `defer wg.Done()` (lexically accessing!), and the invoking routine calls `wg.Wait()` at the end to block until all operations are complete.\n\n**sync.Mutex** / **sync.RWMutex** -- you know these. Guard critical sections from concurrent access. Use `RLock` for concurrent readers, but not concurrent writers.\n\n**sync.Cond** -- lets you wait for signals / broadcasts in goroutines without doing a spinlock / poll. Think about event handlers and broadcasts in Kubernetes -- every time a Job is modified, an event propagates through the k8s control plane, hitting controller reconciliation queues (or not). If you give a bunch of separate, loosely-coordinated goroutines a `sync.Cond` called `syncer`, you can tell each of them to wait via:\n```\nsyncer.L.Lock()\ndefer syncer.L.Unlock()\nc.Wait() // DON'T FORGET TO GUARD THIS!\n```\n\nThen you can call either `c.Signal()` or `c.Broadcast()`:\n1) `Signal`: \"internally, the runtime maintains a FIFO list of goroutines waiting to be signaled; Signal finds the goroutine that’s been waiting the longest and notifies that.\"\n2) `Broadcast`: \"sends a signal to **all** goroutines that are waiting.\"\n\n_Important_: don't forget to guard your waits! A `Cond` signal / broadcast just says _something_ happened -- it doesn't guarantee that your particular condition is met.\n\n**sync.Once** -- Given `var once sync.Once`, `once.Do(fn)` will only do `fn`. If `fn2` is called with `Do`, it won't be done. If `fn` is called again with with `Do`, it won't be done. It truly is just once.\n\n**sync.Pool** -- used to amortize costs for groups of related, expensive objects. Think database connections, or (ironically) thread pools in Java. You can save GC pressure by reusing allocated memory from a pool. A pool is best when it is silently shared by a set of independent concurrent processes.\n\nYou can provide a pool with a `New() interface{}` function at instantiation -- this gives you \"get-or-create\" semantics for `pool.Get()`, e.g. if there's nothing in the pool, it'll create a new pool object based on your passed-in closure.\n\n## Channels\nChannels are used to communicate data between processes. They're composable via `select`. They're typed both by data AND direction.\n\nChannels can be written and read -- you can declare a channel as **bidirectional** (read+write) OR **unidirectional** (just read, just write). A unidirectional channel is automatically cast to a bidirectional channel if needed.\n\nChannels are **blocking** -- reading from a channel will block until a value is available, and writing to a channel will block until a channel has capacity. This is why you don't need things like `sync.WaitGroup` to coordinate, and is also why channels can deadlock -- if all goroutines are asleep and a channel read is blocking, the program won't make progress. This can be prevented both structurally and altogether -- see next chapters.\n\nChannel reads / receives can also return two values, e.g.:\n```\nstringStream := make(chan string)\ngo func() {\n    stringStream <- \"Hello channels!\"\n}()\nsalutation, ok := <-stringStream 1\nfmt.Printf(\"(%v): %v\", ok, salutation)\n```\nThis brings up **closed** channels. We sometimes want to indicate that a channel has nothing more to give to receivers -- think multiple recievers of a single upstream writer. This second return value indicates whether or not or first return value is actually a value put on the channel, OR if it's the default value read from a closed channel.\n\nThis proceeds into range semantics:\n```\nintStream := make(chan int)\ngo func() {\n    defer close(intStream)\n    for i := 1; i <= 5; i++ {\n        intStream <- i\n    }\n}()\n\nfor integer := range intStream {\n    fmt.Printf(\"%v \", integer)\n}\n```\n\nWhen the channel is closed, the `range` will detect it and stop looping.\n\nClosing channels is also useful for unblocking multiple goroutines at once. A similar thing can be done with `sync.Cond` above, but it's easier to close a single channel with `N` receiving goroutines, which will then all be unblocked as they read the default value of a closed channel.\n\nAll channels so far have been **unbuffered** channels -- they have no capacity. **Buffered** channels can be instantiated to hold multiple values, and use the `make` command with just an additional int for capacity. In summary - they're an in-memory FIFO queue for concurrent processes to communicate over. They block writes when full, and reads when empty, same as unbuffered.\n\nChannels can only be closed once. Closing a closed channel is a panic. Doing IO with a nil channel is a deadlock, since they'll never unblock.\n\nKeep in mind the _ownership of channels_ when you're working with them. Keep the ownership scope small and tight, and use the type safety of read-only / write-only channels to verify how channels are passed around. Having a single writer at a time is crucial for preventing deadlocks, closes, etc.\n\n## The select statement\n\n`select` lets you glue together channels. They're what makes channels composable. They look like a `switch`, but they **aren't tested sequentially and don't fall through automatically!** All channel reads and writes in a `select` are considered simultaneously -- this means reads checking for channel values, and writes waiting for buffer space to fill. If no channels are ready, the `select` just blocks.\n\nThis is particularly interesting when _multiple channels simultaneously have something to read/write_. In this case, **Go chooses one of the channels roughly at random**! This means this will provide roughly even counts:\n\n```\nc1 := make(chan interface{}); close(c1)\nc2 := make(chan interface{}); close(c2)\n\nvar c1Count, c2Count int\nfor i := 1000; i >= 0; i-- {\n    select {\n    case <-c1:\n        c1Count++\n    case <-c2:\n        c2Count++\n    }\n}\n\nfmt.Printf(\"c1Count: %d\\nc2Count: %d\\n\", c1Count, c2Count)\n```\n\nIf no channel is ready, you can use `time.After` to time out, or `default` to fall through to other work.\n\nLast thing: `GOMAXPROCS` controls the number of work queues mapped to OS threads. It defaults to `runtime.NumCPU()`, e.g. the number of logical CPUs.\n"
    }
  ]
}