{
  "title": "Introduction to Big Data and Distributed Systems",
  "cells": [
    {
      "type": "markdown",
      "data": "## Storage?\n\n**Big Data Report Card - SESFAC**\n1) Schematized (CSV? Database? Protobuf? Blob? Columnar?)\n2) Execution (human-readable? tooling? SQL?)\n3) Storage-efficient (binary? database?)\n4) Fast (RDBMS? KV? Indexes? Partitioned?)\n5) Available (replicated?)\n6) Consistent (Paxos? Scuttlebutt?)\n\n### Level 1 - CSV on a shared server\n\n1) _D_ — it has structure, but no guarantee row-to-row beyond what the producer provided. Commas break easily, as do pipes. No type information, no versioning possible.\n2) _C-_ — Easy to read and consume, but must exclusively use external tools to parse.\n3) _D+_ - no compression, no encoding, underlying bytes are dependent on platform\n4) _D_ - Access patterns are confined to full scans, regardless of how much you actually need.\n5) _F_ - if it's deleted, the node crashes, retention policies, etc., it's gone.\n6) _F_ - everyone modifies separately, in place, no access control, no history\n\n### Concept 1 — Data formats / IDLs\n\nWhen we begin to work with some data, we'd like some guarantees about that data. Some guarantees we want: established schema, established types, and preferably some compatibility / evolution rules (\"if I add a field to this schema, will readers of the old schema be okay with that?\"). Additionally, once you begin to add information on schema and types, you are able to represent data of that schema more concisely. Think of JSON — it's a weird compromise between field names, types, and data, meaning all JSONs carry field names. If you already have that information, you just need to know which bytes correspond to which fields. If you have type information, you can represent those types more compactly (\"bit packing\"). If you have a lot of records of a type, you can encode them together for even more savings!\n\n### Level 2 — Parquet on a shared server\n\nParquet is a binary storage format designed for analytical tasks, and introduces the idea of columnar data storage.\n\n1) _B_ — schematized on write, columnar access patterns, no versioning\n2) _C+_ — CLI tools for specific access, not human readable, still easy to pass around\n3) _B+_ — Dremel encoding, dictionary encoding, compact binary, compressed, columnar\n4) _A-_ - metadata for seeks, fast deserializing on read, taking only what's necessary\n5) _F_ - no change\n6) _F_ - no change\n\n### Concept 2 — Replication and Partitioning\n\nStated simply:\n1) Replication is duplicating your dataset onto multiple independent nodes for both fault tolerance and performance scaling.\n2) Partitioning is splitting your dataset horizontally (row-wise) to allow for different nodes to store parts of one complete dataset, mostly for performance scalability.\n\nReplication can be single leader-based, multi-leader-based, and leaderless. Partitioning aims to distribute load through consistent hashing while also avoiding hot spots / keys and allowing for range queries.\n\n![IMAGE](quiver-image-url/EFE980FE9F1EB3AA88D1D0A31057F4B5.jpg =1786x930)\n\n### Level 3 — Parquet on HDFS\n\n1) _B_ — no change\n2) _B-_ — a little more complex working with a DFS directly, but now we have Hive and MapReduce!\n3) _B_ — trade space for availability\n4) _B+_ - trade speed for availability\n5) _B+_ - file is replicated to nodes; maybe still limited to rack / AZ / region is dangerous?\n6) _F_ - no change\n\n### Concept 3 - Execution and Computation\n\nHow do we compute on data? Traditionally, it's with imperative programming languages or with declarative query languages.\n\nSQL is a `declarative` language. The user describes what they want to occur using a high-level syntax, and the execution engine examines the current context (data being operated on, server load) and chooses some physical operations to match the promises of your SQL description. You _declare_ what you want to happen, and the execution engine figures out the best way to do it.\n\nMeanwhile, Spark started as an `imperative` DSL of Scala. The `RDD` API allows for low-level manipulation of distributed, partitioned datasets on commodity hardware - you program exactly what you want to happen. Sure, there are declarative aspects — things like shuffles are taken care of for you. Spark moved more declarative with Spark SQL and the `DataFrame` / `Dataset` API — the Tungsten and Catalyst engines allow for both performance and declarative aspects, respectively. \n\nBut where did Spark originally come from? MapReduce!\n\n`MapReduce` was such a powerful win because it abstracted data workflows into a simple lineage maps, sorts and reduces. By allowing the user to perform arbitrary computations on arbitrary data formats on a DFS, users could break out of both declarative languages requiring underlying specialization as well as highly idiosyncratic, proprietary storage formats (duck taped with others via a vaneer of standardization, like ODBC and ANSI). \n\nBut MapReduce in and of itself didn't go far enough! It needed in-memory piping between stages (instead of incurring disk IO for every step), it needed more computation models beyond a map-reduce constraint, it needed data APIs that were performant and usable out of the box. In short, MapReduce was like a really good hammer, whereas Spark is a full toolkit.\n\n### Level 4 — Spark on Parquet on HDFS\n\n1) _B+_ — execution engine makes working with files easier\n2) _A-_ — we have Hive + MR + all of Spark!\n3) _B_ — no change\n4) _A_ — benefits of Parquet + benefits of established, robust execution engine with smart algorithms.\n5) _B+_ — no change\n6) _F_ — no change\n\n### Level 5 — Table in single-node, unpartitioned table in an enterprise RDBMS\n\nHold up, you're missing a huge part of the story here. Why introduce a proprietary format and a special execution engine when we could have both at once in databases?! Just put your CSV into a database and you're good to go, right?! Well, sorta.\n\n1) _B-_ — highly schematized on write, but in propietary format; type info and usage varies between products, although things like ODBC make it better. Evolution possible with database migrations and tooling, but adhoc.\n2) _B-_ — only accessible with tooling and credentials, SQL is good but not perfect, relational model has pros and cons, ORM is difficult and clunky. Declarative language\n3) _B_ — efficient, but proprietary\n4) _B-_ — can be very fast, but requires careful planning (normalization?) and specialized expertise in your product. Concurrent access can cause contention and locking. Access patterns are usually limited to table-based scans and seeks, with limited support for massive analytics\n5) _C+_ — database backups, atomic transactions; no replication to mitigate node failures and no partitioning / sharding\n6) _A_ — follows ACID, transactions, locking, latches, deadlock management, concurrency, different isolation levels. We get this because we have **one** copy of the data, and we just manage access to that data via locking mechanisms\n\n### Level 6 — Table in multi-node, leader-based-replicated, sharded, partitioned table in an enterprise RDBMS\n\nOkay, fine, so let's get some replication for both availability and locality, and let's shard and partition such that we get better concurrent access and speed.\n\n1) _B-_ — no change\n2) _C+_ — no change\n3) _B-_ — replication is redundant, format is still compact\n4) _C+_ - same problems as above, plus the possibility of reading from a less ideal replica\n5) _B+_ — all the above, but now with multiple nodes storing the data; partition / sharding allows for smart R/W distribution\n6) _B_ — writes are confined to leader and are fine, but reads can suffer replication lag and consistency with read-your-writes scenarios. We've entered the world of **eventual consistency**!\n\n### Level 7 — Cassandra\n\n1) _B_ — Schematized on write, can be treated as tables.\n2) _C+_ — only accessible with tooling and credentials, CQL is limited, libraries run the gamut.\n3) _B_ — Binary SSTable on commodity hardware. Data replication incurred.\n4) _B-_ — KV access patterns are fast; indexing can be limited and difficult, range scans depend on your partitioning key and partition hashing algorithm. Hot keys are a problem for underlying IO and consistency. Forcing ACID semantics incurs serious performance penalties.\n5) _B+_ — Partitioned KV with quorum-based replicated writes on commodity hardware. Similar to HDFS!\n6) _C+_ — Eventual consistency and leaderless replication. Last-write-wins is scary, read repair or 2PC is expensive, pushing resolution to the client is taxing.\n\n### Level 100 - Spanner\n\n_A-_ — Paxos state machines for consistency, TrueTime API for total broadcast order, Scuttlebutt for infrastructure; architecture reduces contention incurred by consistency. Still eventually \n\n## Streaming data?\n\nWhat is event sourcing? Given a series of events over time, we should be able to fully reconstruct the state of a system by aggregating down the event set as needed. This pairs nicely with streaming architectures, as events can be produced into messaging systems and then consumed into persistence layers as needed. But streaming architectures present new challenges, foremost among them being — how do I manage all these events, how much state should each event contain, when is a data point complete?\n\nWhen someone produces some analytics via MapReduce or Spark, they are running a batch job over a set period of time with a finite, complete dataset. Analytics are then couched appropriately as \"the known state for this time period\". In a streaming world, however, you can make no assumptions on data completeness. Data might be late, or produced at different cadences. It is up to the streaming application to properly aggregate data and only trigger it for release when it is \"complete\". Other problems become much harder too — how do you join streams? What time windows do you leave for your joined events in two streams to overlap by? What do you do with late data outside of your time windows (\"watermarking\")?\n\n* ACID vs CAP\n* Lambda architecture vs kappa architecture vs CQRS\n* Spark demo"
    }
  ]
}