{
  "title": "Storage and Retrieval",
  "cells": [
    {
      "type": "markdown",
      "data": "Two main storage mechanisms:\n1) Log-based\n2) Page-based\n\n### Log-based\n\nAn append-only sequence of records. May or may not be human-readable; has an order. Traversal aided with indexes. Writes are fast, reads can be fast with indexes.\n\n##### Log Indexing Structures - Hash Tables\nThese are the KV structures you know - preferably:\n* stored in memory with snapshots on disk for recovery\n* undergo compaction concurrently with reads / writes\n* compaction both dedups and combines segments\n\nDeleting a record can be done by appending a `tombstone` - a record that indicates deletion of a key. That deletion will occur on the next compaction.\n\nChecksums help prevent corruption, and a single writer thread helps with concurrency / locking. Sequential writes are always preferable, even for SSDs (and obviously for HDs). Range queries can be tough, though - require lookups of all keys in the hash index!\n\n##### SSTables, LSM-Trees\nSSTables are still log-based, but now the keys are written to disk as sorted keys. Compaction maintains the sort, and moves through segments (key uniqueness maintained per segment), keeping only the newest key upon duplication.\n\nThis supports range queries much better - your hash index can keep offsets for only a few keys, so if you're looking for key \"ccc\" and you have hash index entries for \"aaa\" and \"ddd\", you only need to pull that range. Further, that block can be compressed intelligently for better reads.\n\nThe actual ordering is performed by a `memtable` - an in-memory data structure ideal for sorting (red-black trees, AVL trees). The record is written to a write-ahead log, append-only (for fault tolerance), and then added to the memtable. Once the memtable exceeds some size threshold, it's written to disk as a new SSTable segment.\n\nThis methodology is used by Cassandra, Riak, LevelDB, RocksDB...pretty much all the KV stores. It was originally titled a `Log-Structured Merge-Tree`.\n\nPerformance optimizations are crucial:\n1) Use a `Bloom filter` to avoid scenarios where the key doesn't exist, and thus a request has to scan every hash table for every segment.\n2) Compaction can be `size-tiered` or `leveled` - size-tiered merges newer segments into older, larger segments.\n\n#### B-Trees\nB-Trees are the standard for RDBMSes and have been \"ubiquitous\" since 1970. They work super well.\n\nB-Trees split your keys into ranges, and upon read / write, will navigate those ranges to the appropriate `leaf node`, where there will either be the value for the requested key, or a pointer to the physical location of the value. Adding a key involves finding the appropriate key range, and either adding, or splitting the index page into two new pages to divide the key range.\n\nFundamental here is the `page` - typically pages are written a 4Kb chunks, and correspond well to underlying disk structures and groupings. Also remember the `branching factor`, i.e. how many child inde pages a given page can have. Traversing a B-Tree is `O(log n)` where `n` is the number of keys - this is because a B-Tree will always be a BALANCED tree.\n\nReliability is maintained usually with a WAL (or a transaction log, like SQL Server). Concurrency controls are implemented on pages via latches and locks.\n\nSome optimizations to B-Trees:\n* Copy-on-write â€” a separate page is written when an update goes through, and corresponding parent index pages are rewritten to point there. This also helps for isolation levels in concurrent read / writes.\n* Key shortening - we need only enough information to traverse the tree and dereference the keys successfully. We might not need all of a key for that, but instead just the first _n_ characters of it.\n* B-Trees should correspond as best as possible to the physical disk ordering such that range queries will dereference to contiguous disk locations. This is the idea of a `clustered` vs `nonclustered` index in SQL Server.\n* Variants like B+ Trees include pointers at the leaf level so that range queries don't have to re-traverse index pages to reach multiple leaf pages.\n\n#### Comparing B-Trees and LSM-Trees\nCommon wisdom gives the edge to LSM-Trees on writes and B-Trees on reads, but your mileage DEFINITELY will vary, depending on request size, concurrency, etc.\n\n`Write amplification` and `fragmentation` are concerns with B-Trees - pages split based on their fill factor, which will leave space allocated but unused. Further, B-Trees might write to many more pages, and even the operation of rewriting a full page for a few bits changed is problematic.\n\nLSM-Trees have write amplification as well, but it's usually not as big a concern."
    }
  ]
}