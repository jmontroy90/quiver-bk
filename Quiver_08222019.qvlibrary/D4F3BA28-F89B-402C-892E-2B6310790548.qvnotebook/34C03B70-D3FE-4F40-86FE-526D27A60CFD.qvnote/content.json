{
  "title": "Envoy - Nebula",
  "cells": [
    {
      "type": "markdown",
      "data": "ENVOY -- NEBULA\n\nORDER OF OPERATIONS:\n\nCreate a discovery client (custom struct, include Consul API client + metadata) -- this is used for connecting to Consul for SD info.\n\nCreate a TCP listener based on passed-in port (default 5555). This is the listener that Envoy is configured to connect to. The Envoy node uses the configured Consul Service Discovery pattern to connect to the right Nomad client node that runs Nebula, it connects on a standard EXTERNAL port (per Envoy config), which is 26669 for us. This maps to the exposed Docker port of 5555, which is what this TCP listener is created on. So this is the communication point between Envoy and Nebula, whereas the above discovery client is between Nebula and Consul.\n\t* This is eventually used for the data server, which encompasses interactions between all three.\n\nCreate a new Nebula Manager\n\t1) what is the proxyTag?\n\t\t* Each deployment of Nebula (public, private, corp) has a different provided proxyTag, e.g. \"envoy.eastus2.qa.notjet.net\" for nebula-public.\n\t2) what is the mutex used for, and why is it needed globally?\n\t3) what is this pattern of having a Manager for everything? necessary?\n\nSync all state via the Manager. This is bootstrapping and subscriptions.\n\t1) Create a new empty Cache if this is the first time.\n\t2) Run `Watch` on the Cache's State.\n\nCreate a DataServer instance for getting data from Consul. The Data Server is used to create a GrpcServer, which is used to actually serve Consul data to the TCP listener. Once a GRPC request comes in from Envoy (on some interval / timer), the GRPC Server will run through its registered handlers for the request to reply. So it listens on the port for whomever tries to connect (Envoy could move around).\n\n\nThe following handlers are registered on the main GRPC server that serves Envoy requests:\n\tocgrpc.DefaultServerViews\n\tochttp.DefaultClientViews\n\tnewHealthServer\n\tdataServer -- this is the actual connection to the Consul data server. It's a struct that implements the AggregatedDiscoveryServiceServer interface required by Envoy for doing service discovery. \n\nThe GRPC registers an ADS handler which is the `Server` struct above that implements AggregatedDiscoveryServiceServer. When a request comes in (envoy.DiscoveryRequest), it adds it to the request channel, which is passed into the dataServer's process method. This `process` method \n\nThe following Go HTTP metrics / profiles are available as registered handles on the Nebula admin server HTTP endpoint:\n\t\"allocs\"\n\t\"block\"\n\t\"cmdline\"\n\t\"goroutine\"\n\t\"heap\"\n\t\"mutex\"\n\t\"profile\"\n\t\"threadcreate\"\n\t\"trace\"\n\t\"index\"\n\n\nXDS Server handler `process` method:\n1) We received a service discovery request from Envoy. We take the nodeId and proxyId from the Envoy request to generate watchers for that Envoy. The Nebula Manager implements the Watcher interface, which lets you start watching a particular Envoy. We check what kind of xDS request it was, \n\nNebula Manager: handles the built-in Consul client, manages a global mutex lock, a map of watches (e.g. snapshots of discovery state), and finally Nebula state (ultimately a struct of cached Services, endpoints, clusters, and routes - the mutable, refreshed set of discovery information that Nebula queries from Consul).\n\nManager has State which has a Cache which has Services, Endpoints, Clusters\n\nCatalogWatcher - cached state + a map of ServiceWatchers\nServiceWatcher - watches an individual Service in Consul based on the provided `serviceName`, which can then be used in a Consul query.\n\nTHESE WATCHERS ARE DIFFERENT FROM THE ENVOY WATCHERS THAT ARE REGISTERED WHEN A MESSAGE IS RECEIVED!!\n\nThe data manager syncs up to Consul and uses the CatalogWatcher to `fetch` everything on every defined interval. When it fetches the catalog, it diffs with its current state in memory, and spins off a goroutine to keep each added service in sync between Consul and the Nebula state.\n\nThe `run` method on it is responsible for handling requests that Envoy sends for service discovery.\n\n\nCalling `Watch` on the Manager allows you to add an Envoy to be tracked by Nebula. This makes that Envoy sync-able, e.g. you can broadcast received Consul snapshots to that Envoy now.\n\nCalling Watch on the Manager's `state` is DIFFERENT! That just returns a channel that is used to constantly receive snapshots from Consul.\n\nIMPORTANT FUNCTIONS:\n`func (c *Cache) Update(service *discovery.Service) error { ... }`\n\t* this updates the Nebula state for an individual service in Consul with discovery information.\n\n`func (s *State) run() { ... }`\n\t* This is only done as a goroutine!\n\t* Two cases:\n\t\t1) If a one-second timer goes off, it marshalls its state into Proto, and sends that marshalled state to the state's snapshot channel.\n\t\t2) If the State gets a request from Envoy, it sends that same marshalled Proto state into the State's reply channel.\n\t* Basically Envoy and Nebula have two-way communication. Envoy can send requests, but Nebula can also force-push Consul snapshots.\n\t* The snapshot channel is passed back to the Sync function, which broadcasts the snapshot on every receive of a snapshot.\n\t* The broadcast function pushes to all watchers, which will include our Envoy requester!\n\n`func (s *Server) process(stream ADSStream, reqCh <-chan *envoy.DiscoveryRequest) error { ... }`\n\t* The first case registers any Envoy that sends a request to Nebula as something to be watched via the Watchers interface.\n\t* The second case logs that a snapshot was received \n\n`func (m *Manager) Watch(proxyId string) (<-chan *Snapshot, func()) { ... }`\n\t* The `proxyId` here is the node id from a requesting Envoy instance. It gets added to the Manager's `watchers` list as a channel that gets populated with the Manager's state.\n\t* The Manager's state gets propagated to Envoy via the watchers map.\n\t* When an Envoy is first added to watchers, the initial Consul state is pushed. From there, the watcher channel corresponding to the watched Envoy is returned to the XDS / gRPC server to monitor indefinitely via the `process` method's select branching.\n\n`func (h *xdsHandler) SendIfNew(resources []proto.Message, version string, nonce *uint64) error { ... }`\n\t1) If no Envoy discovery request came in, return nil\n\t2) If the version wasn't bumped, return nil\n\t3) Construct the response by marshalling into Proto, switching on what kind of request it was\n\t4) Send the constructed discovery response asynchronously in a goroutine, with a hard-coded timeout of five seconds\n\nIMPORTANT QUESTIONS TO BE ABLE TO ANSWER:\n1) How often does Envoy send a discovery request to Nebula?\n    * A long poll that aggregates over each second.\n2) How long does Nebula try to send discovery responses to Envoy before timing out?\n\t* Five seconds, async on a goroutine. It's hard-coded currently. \"timeout reached trying to send on stream\"; xds.go:273\n3) What discovery data does Nebula currently send?\n\t* Only {ClusterType, EndpointType, RouteType} -- ListenerType and SecretType aren't set up (xds.go:177)\n4) If a service is `phased` but doesn't specify `routing` or `assignment` specifically, what's the behavior?\n  * Routing only.\n\n\nIMPORTANT GOROUTINES:\nXDS / gRPC server (xds.go:68) -- receives Discovery Requests from Envoy for resources; these requests are handled by xds.go:process(...)\n\n\n"
    }
  ]
}