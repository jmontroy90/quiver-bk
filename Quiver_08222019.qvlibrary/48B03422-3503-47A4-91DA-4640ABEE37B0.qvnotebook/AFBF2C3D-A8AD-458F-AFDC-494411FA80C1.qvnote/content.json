{
  "title": "Chapter 12: Service Discovery",
  "cells": [
    {
      "type": "markdown",
      "data": "Kubernetes enables lots of mechanisms for service discovery. Currently, we use Envoy as our service registry, which uses its xDS protocol reading from Consul's service registry, which gets its info from Nomad. Envoy is able to L4 / L7 load balancing, and reverse proxying based on the service discovery information.\n\n### Internal Service Discovery\n\nWe use a `Service`. This specs down to a particular label as such:\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: random-generator\nspec:\n  selector:\n    app: random-generator\n  ports:\n  - port: 80\n    targetPort: 8080\n    protocol: TCP\n```\n\nHere, this defaults to `clusterIP` as its type, which means the corresponding app (here, random-generator) gets a cluster-specific private, permanent IP that can be used forever by other Kubernetes service to find it.\n\nOther Kubernetes services find this private IP in one of two ways:\n1) **Environmental Variables** -- all applied Services will propagate their new cluster IP to the environmental variables of all Deployments performed AFTER the Service is applied. The environmental variables look like:\n    ```\n    RANDOM_GENERATOR_SERVICE_HOST=10.109.72.32\n    RANDOM_GENERATOR_SERVICE_PORT=8080\n    ```\n2) **Kubernetes DNS** -- Kubernetes manages its own DNS, which allows all services to have a common FQDN available for all other services. This works when each node's `kube-proxy` picks up the new Service and applies it to its iptables, allowing the virtual IPs and FQDNs to be resolved appropriately.\n\nNote the following:\n* **Session stickiness** is only available by IP, since this service works as an L4 router.\n* Readiness probes will remove bad Services from DNS as detected.\n* the iptables add via kube-proxy is IP only!! So TCP / UDP yes, ICMP no! **Don't try to ping for connectivity**!!\n\n### Manual Service Discovery\n\nYou can hit external servies from Kubernetes using `Endpoints`.\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: external-service\nspec:\n  type: ClusterIP\n  ports:\n  - protocol: TCP\n    port: 80\n```\n\nCouple this with:\n\n```\napiVersion: v1\nkind: Endpoints\nmetadata:\n  name: external-service\nsubsets:\n  - addresses:\n    - ip: 1.1.1.1\n    - ip: 2.2.2.2\n    ports:\n    - port: 8080\n```\n\nYou can also use a type of `ExternalName` to use an FQDN CNAME to point externel to Kubernetes.\n\n### Service Discovery from Outside the Cluster\n\nMethods for external discovery of Kubernetes apps:\n1) `type: NodePort`. This opens a port on all nodes that will route to a certain set of pods based on labels, using the Service.\n![IMAGE](quiver-image-url/01A20D659FA288288845F5813D052B33.jpg =659x714)\n\n2) Cloud-provided `LoadBalancer` type. This adds a Service, a NodePort, and adds a cloud-backed LB to aid in routing.\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: random-generator\nspec:\n  type: LoadBalancer\n  clusterIP: 10.0.171.239\n  loadBalancerIP: 78.11.24.19\n  selector:\n    app: random-generator\n  ports:\n  - port: 80\n    targetPort: 8080\n    protocol: TCP\nstatus:\n  loadBalancer:\n    ingress:\n    - ip: 146.148.47.155\n```\n3) The `Ingress` type. This is an L7 router that does more complex routing like Envoy. The YAML even looks like poor man's Envoy.\n```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: random-generator\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /\n        backend:\n          serviceName: random-generator\n          servicePort: 8080\n      - path: /cluster-status\n        backend:\n          serviceName: cluster-status\n          servicePort: 80\n```\n![IMAGE](quiver-image-url/2A5A94565A69774F8237512F3BA23A65.jpg =659x678)\n\nHere's a summary table of everything.\n\n![IMAGE](quiver-image-url/24DC62EAFF20E2F061195734D02D3ED7.jpg =1400x1288)"
    }
  ]
}