{
  "title": "Tuning Apache Spark for Large Scale Workloads",
  "cells": [
    {
      "type": "markdown",
      "data": "[Link to video](https://www.youtube.com/watch?v=5dga0UT4RI8)\n\nTo find out more:\n* Shuffle Read Blocked Time\n* Flame Graphs in Spark + Nomad\n\nHeuristics for number of mappers / reducers - scale based on input dataset size!\n![IMAGE](quiver-image-url/57B98CB8BAA1F157329ED7E0FB108053.jpg =698x278)\n#### Dynamic Executor Allocation\nAs task queue length increases, executors are allocated by the cluster manager. Decreases in queue length cause deallocation on an interval, per settings below:\n\n![IMAGE](quiver-image-url/D7258A4909FFA9D61D0CCC0724BE4D92.jpg =596x154)\n\n#### Memory Allocation\nYou can tune this based on your workloads -- lots of data and embarrassingly parallel? Or maybe less data but LOTS of `ShuffleMapTask` going on.\n![IMAGE](quiver-image-url/838FB2A331CCC39093B1B3AEAFACD227.jpg =1014x366)\n\nWe should use Parallel GC instead of G1GC in order to avoid memory fragmentation on huge page allocation (>32MB is beyond G1GC's max allocation size).\n\n`spark.executor.extraJavaOptions = -XX:ParallelGCThreads=4 -XX:+UseParallelGC`\n\nRemember we can use off-heap allocation too to speed things up.\n\n#### Improving IO\n`spark.io.compression.lz4.blockSize = 512KB` yielded a significant decrease in shuffle file size (-20%).\n\nAlso, for example for shuffle spills, memory buffers can reduce IO costs.\n\n#### Shuffle Server Optimizations\nEvery time a reducer (executor) issues a shuffle fetch request (i.e. driver RPCs an event telling that node to find its data), the executor shuffle service reads a persisted index file for its relevant shuffle partitions to seek-access the persisted shuffle files from some underlying store.\n\nApparently the index file was reloaded from disk on every shuffle fetch request. Facebook added caching with an LRU eviction policy.\n\n`spark.shuffle.service.index.cache.entries = 2048`\n\n#### Other Facebook fixes:\n* Multi-Threaded Event Processors for driver task queue build-up\n* Fetch Failures had a bug which caused multiple retries for a single fetch failure type\n* `spark.rpc.io.serverThreads` -- on huge jobs, lots of events being tossed around via netty RPC calls, let's \n\n"
    }
  ]
}